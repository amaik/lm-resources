# LM-resources
A summary of resources regarding language modeling.

## Transformer
### Transformer
- [x] Paper - Attention is all you need - https://arxiv.org/abs/1706.03762  
- [ ] Blog - The annotated transformer - https://nlp.seas.harvard.edu/2018/04/03/attention.html
- [x] Blog - The illustrated transformer - https://jalammar.github.io/illustrated-transformer/
- [x] Paper - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding - https://arxiv.org/abs/1810.04805
- [ ] Paper - RoBERTa: A Robustly Optimized BERT Pretraining Approach - [link](https://arxiv.org/abs/1907.11692)
- [x] Paper - ALBERT: A Lite BERT for Self-supervised Learning of Language Representations - [link](https://arxiv.org/abs/1909.11942) 
- [x] Blog - Visualized Bert/Elmo - http://jalammar.github.io/illustrated-bert/
- [ ] Blog - BERT First time - http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/
- [ ] Notebook - Bert end-to-end - fine tuning - [link](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb#scrollTo=7wzwke0sxS6W)
- [ ] Paper - Music Transformer - https://arxiv.org/pdf/1809.04281.pdf
- [x] Paper - TransformerXL - https://arxiv.org/abs/1901.02860
- [ ] Paper - XLNet - https://arxiv.org/abs/1906.08237

### GPT2/3
- [ ] Paper - GPT1 - https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf
- [x] Paper - GPT2 - https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
- [ ] Paper - GPT3 - https://arxiv.org/abs/2005.14165
- [x] Blog - GPT1 - https://openai.com/blog/language-unsupervised/
- [x] Blog - GPT2 - https://openai.com/blog/better-language-models/
- [x] Blog - The illustrated GPT2 - http://jalammar.github.io/illustrated-gpt2/

## LM General
- [ ] Paper - Allow LMs to fill in the gap - https://arxiv.org/abs/2005.05339
- [ ] Paper - Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism - [link](https://arxiv.org/abs/1909.08053)

## Corpora
- [ ] Paper - BooksCorpus - https://arxiv.org/abs/1506.06724

## Tokenization
### Subword modelling
- [ ] Blog - Various algorithms - https://medium.com/@makcedward/how-subword-helps-on-your-nlp-model-83dd1b836f46
- [x] Paper - Byte-pair representation - https://arxiv.org/abs/1508.07909  
- [ ] **Paper - Word-piece representation - https://arxiv.org/abs/1609.08144**


## Machine Learning - General
- [ ] Paper - Convolutional s2s models(learned positional embeddings) - https://arxiv.org/abs/1705.03122
- [ ] Paper - Layer normalization - https://arxiv.org/abs/1607.06450
- [ ] Paper - Adam: A Method for Stochastic Optimization - https://arxiv.org/abs/1412.6980
- [ ] Paper - Dropout - http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf
- [ ] Paper - Label smoothing - https://arxiv.org/abs/1512.00567
- [ ] Paper - One model to learn them all (Task conditioning) - https://arxiv.org/abs/1706.05137
- [ ] Paper - Shannon Entropy - https://arxiv.org/ftp/arxiv/papers/1405/1405.2061.pdf
- [ ] Paper - Glove - (link)[https://nlp.stanford.edu/pubs/glove.pdf]

## Topic Modelling
- [ ] Paper - Topic modelling with Wasserstein Autoencoders - https://arxiv.org/abs/1907.12374

## Text Summarization
- [ ] Paper - Sample Efficient Text Summarization Using a Single Pre-Trained Transformer - [link](https://arxiv.org/abs/1905.08836)


## Misc
- [x] Website - Summary of papers with code. Leaderboard of benchmarks. - https://paperswithcode.com/task/language-modelling
